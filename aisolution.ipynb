import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.regularizers import l2

# Load VGG16 as a feature extractor (excluding the top classification layers)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(400, 400, 3))

# Freeze the first few layers of the model
for layer in base_model.layers[:15]:
    layer.trainable = False

# Create new top layers for classification on the four classes
x = Flatten()(base_model.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)  # Dropout for regularization
x = Dense(4, activation='softmax')(x)  # Four classes

# Combine the base model and the new layers
model = Model(inputs=base_model.input, outputs=x)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# View the structure of the model
model.summary()

from sklearn.model_selection import train_test_split

# Assuming X and y are your data and labels loaded into NumPy arrays
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)  # Split the data

# Preprocess the data
X_train = tf.keras.applications.vgg16.preprocess_input(X_train)
X_val = tf.keras.applications.vgg16.preprocess_input(X_val)

# Convert labels to categorical (one-hot encoding)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)
y_val = tf.keras.utils.to_categorical(y_val, num_classes=4)

# Train the model with validation data
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=10,
    validation_data=(X_val, y_val)  # Include validation data here
)